---
title: "[CS] OS: 메모리와 캐시"
author: TaemHam
date: 2023-02-20 09:00:00 +0900
categories: [CS, OS]
tags: [CS, OS, Memory, Cache, VirtualMemory, Memory Allocation]
---

![](https://files.codingninjas.in/blog_2-4-1024x536-1-18372.png)

## 메모리

메모리 계층은 **레지스터, 캐시, 메모리, 저장장치**로 구성되어있다.

![](https://velog.velcdn.com/images%2Fyu-jin-song%2Fpost%2Ff9c8088c-0fec-4dad-ac95-ddf3601aa1d4%2F%EB%A9%94%EB%AA%A8%EB%A6%AC_%EA%B3%84%EC%B8%B5_%EA%B5%AC%EC%A1%B0.png)

* 레지스터 : CPU안에 있는 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적음
* 캐시 : L1, L2캐시를 지칭
* 주기억장치 : 메모리 즉 RAM 지칭
* 보조기억장치 : HDD, SDD 지칭

램은 하드디스크로부터 일정량의 데이터를 복사해 임시로 저장하고, 이를 필요 시마다 CPU에 빠르게 전달한다. 계층 위로 올라갈수록 속도는 빨라지지만 용량이 작아지고 속도는 빨라진다.

속도가 빠른데도 계층으로 나누어진 이유는 **경제성**, 즉, 비싸기 때문이다.

### 캐시

캐시는 **데이터를 미리 복사해 놓는 임시 저장소**로, 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리이다.

정보는 보통 어떤 저장장치에 보관되는데, 정보가 저장된 저장공간에 따라 불러오는 속도가 다르다. 예를 들어 주기억장치 에 있는 프로그램이나 데이터들은 보조기억장치에서 불러올 때보다 훨씬 빠르게 불러온다. 그러나 중복되어 불려지는 데이터나 프로그램의 부분은 더욱 빨리 불러와질 필요가 있었고, 이를 위해 더 빠른 장치인 캐시에 해당 데이터를 저장하여 불러와 성능을 향상시키는 것이다.

하지만 캐시는 크기가 제한되어 있기 때문에 캐시 관리는 중요한 설계 문제로 성능을 크게 좌지우지한다. 캐시는 **"이 데이터가 자주 사용되는가?"**를 판단해 설정하는 것이 좋다. 자주 사용되는지에 대한 근거가 되는 것을 **지역성**이라고 하며, 지역성은 **최근 사용한 데이터에 다시 접근하려는 특성**인 시간 지역성(temporal locality)과 **최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하려는 특성**인 공간 지역성(spatial locality)로 나뉜다.

#### 캐시히트, 캐시미스

![](https://velog.velcdn.com/images/ssongjh55/post/e0d8706c-62fd-458f-af92-2b62182a60e3/image.png)

**캐시에서 원하는 데이터를 찾는 것**을 캐시히트라고 하며, **캐시에 없어서 메모리로 가서 데이터를 찾아오는 것**을 캐시미스라고 한다.

캐시 히트가 일어나면, 제어장치를 거쳐 데이터를 가져온다. 위치도 가깝고 CPU 내부 버스 기반으로 작동하기 때문에 빠르다.

캐시 미스가 일어나면, 메모리에서 데이터를 가져온다. 시스템 버스를 기반으로 작동하기 때문에 느리다.

#### 캐시의 사례

* 웹 브라우저의 캐시

소프트웨어적인 대표적인 캐시로는 웹 브라우저의 **쿠키, 로컬 스토리지, 세션 스토리지**가 있다. 보통 사용자의 커스텀한 정보나 인증 모듈 관련 사항들을 웹 브라우저에 저장해서 추후 서버에 요청할 때 자신을 나타내는 아이덴티티나 중복 요청 방지를 위해 쓰인다.

* 데이터베이스의 캐시

데이터베이스 시스템을 구축할 때도 메인 데이터베이스 위에 **레디스(redis) 데이터 베이스 계층을 '캐싱 계층'으로 둬서 성능을 향상**시키기도 한다.

## 메모리 관리

### 가상 메모리

가상 메모리는 메모리 관리 기법의 하나로, 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 것을 말한다.

이때 **가상적으로 주어진 주소를 가상 주소**(Logical address)라고 하며, **실제 메모리 상에 있는 주소를 실제 주소**(Physical address)라고 한다. 가상 주소는 메모리관리장치에 의해 실제 주소로 변환되며, 이 덕분에 사용자는 실제 주소를 의식할 필요없이 프로그램을 구축할 수 있다.

가상 메모리는 가상 주소와 실제 주소가 매핑되어 있고 프로세스의 주소 정보가 들어있는 **페이지 테이블**로 관리되는데, 이때 속도 향상을 위해 메모리와 CPU 사이에서 주소변환을 해주는 캐시인 TLB를 사용한다.

만약 가상 메모리에는 존재하지만, 실제 메모리엔 없는 데이터를 접근할 경우, 페이지 폴트가 발생한다. 이때 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고, 하드디스크의 일부분을 마치 메모리처럼 불러와 사용하는 것을 **스와핑**(Swapping)이라고 한다. 스와핑이 일어나는 과정은 다음과 같다.

1. CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩을 발생시켜 운영체제에 알린다.
2. 운영체제는 CPU의 동작을 잠시 멈춘다.
3. 운영체제는 페이지 테이블을 확인하여 페이지 테이블을 확인하여 가상 메모리에 페이지(가상 메모리를 사용하는 최소 크기 단위)가 존재하는지 확인한다.
  없으면 프로세스를 중단하고 현재 물리 메모리에 비어있는 프레임(실제 메모리를 사용하는 최소 크기 단위)이 있는지 찾는다.
  물리 메모리에도 없다면 스와핑이 발동된다.
4. 비어있는 프레임에 해당 페이지는 로드하고, 페이지 테이블을 최신화 한다.
5. 중단되어있던 CPU를 다시 실행한다.

메모리에 너무 많은 프로세스가 동시에 올라가면서 스와핑이 너무 많이 일어나 페이지 폴트율이 높아지는 것을 **스레싱**(Thrashing)이라고 한다. 페이지 폴트가 일어나면 CPU 사용이 낮아지고, CPU 사용률이 낮아지면 운영체제는 CPU가 한가한 걸로 파악해 메모리에 더 많은 프로세스를 올리려고 하기에 악순환이 반복된다. 이를 해결하기 위한 방법으로는, 과거 사용 이력을 통해 페이지 집합을 만들어 미리 메모리에 올리는 작업 세트(Working set), 프레임을 동적으로 조절해 페이지 폴트 빈도를 조절하는 PFF(Page Fault Frequency)가 있다.

### 메모리 할당

메모리에 프로그램을 할당할 때는 **시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당**하는데, 연속할당과 불연속할당으로 나뉜다.

#### 연속 할당 

연속 할당은 **메모리에 '연속적'으로 공간을 할당하는 것**을 말한다. 메모리를 미리 나누어 관리하는 고정 분할 방식, 매 시점 프로그램의 크기에 맞게 메모리를 분할하는 가변 분할 방식으로 나눌 수 있다.

* 고정 분할 방식은 메모리를 미리 나누어 사용하기에 융통성이 없어 내부 단편화가 발생한다.

* 가변 분할 방식은 매 시간 프로그램의 크기에 맞게 동적으로 공간을 할당한다. 내부 단편화는 발생하지 않지만 외부 단편화가 발생할 수 있다.
 
  홀 : 할당할 수 있는 비어있는 메모리 공간
  내부 단편화 : 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 발생하는 상태
  외부 단편화 : 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 상태

#### 불연속 할당

불연속 할당은 **메모리를 연속적으로 할당하지 않는 방법**으로, 현대 운영체제가 쓰고 있으며, 대표적으로 페이징 기법이 있다.

* 페이징(Paging)
페이징은 프로세스를 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 할당하는 방식을 말한다.
홀의 크기가 균일하지 않은 문제가 없어지지만, 주소 변환이 복잡해진다.

* 세그멘테이션 (Segmentation)
세그멘테이션은 페이지 단위가 아닌, 의미 단위인 세그먼트 단위로 나누는 방식을 말한다. 의미 단위는 코드와 데이터로 나눌 수도 있고, 코드 내의 함수를 단위로 나눌 수도 있다.
보안 측면에서 장점을 가지지만, 홀 크기가 균일하지 않은 단점이 있다.

* 페이지드 세그멘테이션 (Paged Segmentation)
페이지드 세그멘테이션은 프로그램의 의미 단위인 세그먼트로 나눠 공유나 보안 측면에 강점을 두고, 임의의 길이가 아닌 동일한 크기의 페이지 단위로 나누는 것을 말한다.

#### 페이지 교체 알고리즘

스와핑이 많이 일어나지 않도록 캐싱할 데이터를 선택하는 것이 중요하다. 

* 오프라인 알고리즘 / OPT (Optimal)
먼 미래에 참조될 페이지와 현재 할당된 페이지를 바꾸는 알고리즘이다.
미래에 참조할 프로세스를 알 수 없기 때문에 사용할 수 없는 알고리즘이나, 효율적인 알고리즘을 선택하는데 있어 기준을 제공하는 데 의의를 둔다.

* FIFO (First In First Out)
가장 먼저 온 페이지를 교체 영역에 가장 먼저 올려두는 것을 말한다.

* LRU (Least Recentle Used)
가장 오래된 페이지를 바꾸는 알고리즘이다. 페이지가 참조되면, 교체 순서의 가장 뒤로 밀어내는 방식이다.
가장 오래된 것을 파악하기 위해 계수기, 스택 등을 두어야하는 문제점이 있다.

* NUR (Not Used Recently)
최근에 사용되지 않은 페이지를 교체하는 알고리즘이다. 참조 비트를 두어, 한 번 참조된 페이지는 교체할 순서가 왔을 때에도 교체 되지 않고 한 번 넘어가는 방식이다.

* LFU (Least Frequently Used)
가장 참조가 적은 페이지를 교체하는 알고리즘이다.


## 예상 질문

* 캐시란 무엇인가요?

<details>
<summary>답변</summary>

1. 캐시란, 데이터를 미리 복사해두는 임시 저장공간을 말합니다. 캐시는 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위해 사용됩니다.
2. 모든 데이터를 캐시에 담을 수 없기 때문에 소수의 데이터를 선별해 담는데, 이를 판단할 때 사용되는 것이 지역성입니다.
3. 지역성은 시간 지역성, 공간 지역성으로 나뉩니다. 
4. 시간 지역성이란, 최근 사용한 데이터에 다시 접근하려는 특성을 말합니다.
5. 공간 지역성이란, 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하려는 특성을 말합니다.

</details>

---

* 가상 메모리가 무엇인지 설명해 주세요.

<details>
<summary>답변</summary>

1. 가상 메모리란, 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화해서 사용자들에게는 매우 큰 메모리로 보이게 만드는 것을 말합니다.
2. 이 때, 가상적으로 주어지는 주소를 가상 주소, 실제로 데이터가 존재하는 주소를 실제 주소라고 하는데, 가상 주소는 메모리 관리 장치에 의해 실제 주소로 바뀌기 때문에, 사용자는 실제 주소를 의식 할 필요 없이 프로그램을 만들 수 있게 되는 것입니다.

</details>

---

* 메모리 단편화는 무엇인지 설명해 주세요.

<details>
<summary>답변</summary>

1. 메모리 단편화란, 프로세스를 메모리에 할당 할 때, 프로세스가 들어갈 빈 공간이 충분히 있음에도, 그 공간이 잘게 나누어져 실제로는 사용이 불가능한 상태를 말합니다.
2. 메모리 단편화는 내부 단편화와 외부 단편화로 구분됩니다.
3. 내부 단편화란, 메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 공간이 낭비 되는 상황을 말합니다.
4. 외부 단편화란, 사용 중인 메모리 사이사이 빈 공간이 프로세스를 할당하기에 너무 작아 공간이 낭비 되는 상황을 말합니다.

</details>

---

* 페이징 기법과 세그멘테이션 기법의 차이점에 대해 설명해 주세요.

<details>
<summary>답변</summary>

1. 페이징과 세그멘테이션 기법 모두 메모리 할당 시에 연속적인 메모리 공간이 아닌 곳에 할당하는, 불연속 할당에 속하는 기법들입니다.
2. 페이징의 경우, 프로세스를 동일한 크기로 나눠 서로 다른 위치에 할당시키는 방법을 말합니다.
3. 세그멘테이션의 경우, 프로세스를 의미 단위의 다른 크기로 나눠 다른 위치에 할당시키는 방법을 말합니다.
4. 페이징을 사용한다면, 홀의 크기가 동일해 외부 단편화 문제를 해결할 수 있으나, 페이지와 프로세스의 크기가 딱 맞아 떨어지지 않아 내부 단편화 문제가 생길 수 있습니다.
5. 세그멘테이션을 사용한다면, 의미 단위로 딱 맞게 나눠 내부 단편화 문제를 해결할 수 있으나, 크기가 제각각이므로 프로세스가 메모리를 해제했을 때 외부 단편화 문제가 생길 수 있습니다.

</details>

---

* 페이지 교체 알고리즘에 대해 설명해주세요.

<details>
<summary>답변</summary>

1. 페이지 교체 알고리즘이란, 캐시가 가득 차 페이지를 교체해야할 상황에 캐시를 최소한으로 교체시키기 위해 어느 페이지를 탈락시킬지를 결정하는 알고리즘입니다.
2. 종류는 대표적으로 OPT, FIFO, LRU, LFU, NUR 등이 있습니다.
* OPT는 가장 먼 미래에 참조될 페이지를 교체하는 기법으로, 미래를 알 수 없기 때문에 실현 가능성이 없는 기법이지만, 최선의 알고리즘에 대한 기준이 되는 기법입니다.
* FIFO는 가장 먼저 들어온 페이지가 가장 먼저 교체되는 기법입니다. 선입선출의 구조이기 때문에 구현이 가장 쉽습니다.
* LRU는 가장 과거에 사용됐던 페이지가 먼저 교체되는 기법입니다. 페이지가 참조되었다면 교체 순서를 가장 나중으로 미루는 방식으로 구현합니다.
* LFU는 가장 적게 참조된 페이지가 먼저 교체되는 기법입니다.
* NUR은 최근에 참조되지 않은 페이지를 교체하는 기법입니다. 페이지 참조 비트를 두어, 참조 되었다면 교체 순서에 교체 당하지 않고 넘어가는 방식으로 구현합니다. 

</details>

## 참고 자료
***

* [캐시와 메모리 할당](https://velog.io/@ssongjh55/%EC%BA%90%EC%8B%9C%EC%99%80-%EB%A9%94%EB%AA%A8%EB%A6%AC-%ED%95%A0%EB%8B%B9)
* [Memory Management in Operating System](https://www.codingninjas.com/codestudio/library/memory-management-in-operating-system)
* [[OS] 페이지 교체 알고리즘 - FIFO/LRU/LFU/MFU/NUR](https://doh-an.tistory.com/28)